{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import feature\n",
    "from tqdm import tqdm\n",
    "\n",
    "CHARACTERS = [\"louie\", \"tommy\", \"andy\", \"ora\"]\n",
    "TRAIN_PATH = \"C:/Users/Matei/Downloads/CAVA-2022-Tema2/antrenare/\"\n",
    "POSITIVE_PATH = \"dataset/train/positives/\"\n",
    "NEGATIVE_PATH = \"dataset/train/negatives/vertical/\"\n",
    "\n",
    "VALIDATION_PATH = \"C:/Users/Matei/Downloads/CAVA-2022-Tema2/validare/Validare/\"\n",
    "VALIDATION_ANN = \"C:/Users/Matei/Downloads/CAVA-2022-Tema2/validare/\"\n",
    "VALIDATION_P = \"dataset/validation/positives/\"\n",
    "VALIDATION_N = \"dataset/validation/negatives/\""
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract faces from train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def get_annotations(character):\n",
    "    annotations_file = open(TRAIN_PATH + character + \"_annotations.txt\")\n",
    "    annotations = annotations_file.read().splitlines()\n",
    "    annotations_file.close()\n",
    "\n",
    "    return annotations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def is_valid_position(img, pos):\n",
    "    if any(p < 0 for p in pos):\n",
    "        return False\n",
    "    if pos[0] >= img.shape[1] or pos[1] >= img.shape[1]:\n",
    "        return False\n",
    "    if pos[2] >= img.shape[0] or pos[2] >= img.shape[0]:\n",
    "        return False\n",
    "    return True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def extract_faces_from_annotations(character, source, positive_path, cutout=12):\n",
    "    global count\n",
    "    border = 0\n",
    "\n",
    "    source += (character + \"/\")\n",
    "    annotations = get_annotations(character)\n",
    "\n",
    "    for annotation in tqdm(annotations):\n",
    "         image_name, x_min, y_min, x_max, y_max, name = annotation.split()\n",
    "         x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
    "         save_path = positive_path + name + \"/\"\n",
    "         dict[name] += 1\n",
    "         img = cv.imread(source + image_name)\n",
    "         face = img[y_min:y_max, x_min:x_max, :]\n",
    "         count += 1\n",
    "         cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "         pos = [x_min - cutout // 2, x_max + cutout // 2, y_min - cutout // 2, y_max + cutout // 2]\n",
    "         if is_valid_position(img, pos):\n",
    "            face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "            count += 1\n",
    "            cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "         if img.shape[0] >= 30 and img.shape[1] >= 30:\n",
    "             pos = [x_min, x_max, y_min, y_max]\n",
    "             pos[border % 4] += cutout\n",
    "             if is_valid_position(img, pos):\n",
    "                 face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                 count += 1\n",
    "                 cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "             pos[border % 4] -= 2*cutout\n",
    "             if is_valid_position(img, pos):\n",
    "                 face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                 count += 1\n",
    "                 cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "             if border % 4 == 0:\n",
    "                 pos = [x_min - cutout // 2, x_max, y_min - cutout // 2, y_max]\n",
    "                 if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "             elif border % 4 == 1:\n",
    "                 pos = [x_min + cutout // 2, x_max, y_min + cutout // 2, y_max]\n",
    "                 if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "             elif border % 4 == 2:\n",
    "                 pos = [x_min, x_max + cutout // 2, y_min, y_max + cutout // 2]\n",
    "                 if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "             elif border % 4 == 3:\n",
    "                 pos = [x_min, x_max + cutout // 2, y_min, y_max + cutout // 2]\n",
    "                 if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "         border += 1\n",
    "    print(count)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1353/1353 [00:06<00:00, 198.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2576/2576 [00:10<00:00, 256.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1435/1435 [00:06<00:00, 222.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1872/1872 [00:07<00:00, 248.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "dict = {\"andy\": 0, \"louie\":0, \"ora\":0, \"tommy\":0, \"unknown\":0}\n",
    "for character in CHARACTERS:\n",
    "    extract_faces_from_annotations(character, TRAIN_PATH, POSITIVE_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "louie 2042\n",
      "tommy 1031\n",
      "andy 1647\n",
      "ora 1346\n",
      "1170\n"
     ]
    }
   ],
   "source": [
    "for character in CHARACTERS:\n",
    "    print(character, dict[character])\n",
    "print(dict[\"unknown\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analyze proportions for every character"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_ratio(character, source):\n",
    "    source += (character + \"/\")\n",
    "    ratios = []\n",
    "\n",
    "    for c in CHARACTERS:\n",
    "        annotations = get_annotations(c)\n",
    "        for annotation in annotations:\n",
    "            image_name, x_min, y_min, x_max, y_max, name = annotation.split()\n",
    "            x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
    "            if name == character:\n",
    "                width = x_max - x_min + 1\n",
    "                height = y_max - y_min + 1\n",
    "                ratios.append(height/width)\n",
    "\n",
    "    return sum(ratios) / len(ratios)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for character in CHARACTERS:\n",
    "    print(character + \":\", compute_ratio(character, TRAIN_PATH))\n",
    "print(\"unknown:\", compute_ratio(\"unknown\", TRAIN_PATH))\n",
    "\n",
    "# width/height\n",
    "# louie: 1.251815758043986\n",
    "# tommy: 1.3285152584256952\n",
    "# andy: 0.6870738648331448\n",
    "# ora: 0.7801411367617421\n",
    "# unknown: 0.9044525116339853\n",
    "\n",
    "# height/width\n",
    "# louie: 0.814094476628571\n",
    "# tommy: 0.7733086598193187\n",
    "# andy: 1.4993275758468239\n",
    "# ora: 1.2960066470770064\n",
    "# unknown: 1.1593202925732515"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract negative examples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def intersection_over_union(box_a, box_b):\n",
    "    x_min = max(box_a[0], box_b[0])\n",
    "    y_min = max(box_a[1], box_b[1])\n",
    "    x_max = min(box_a[2], box_b[2])\n",
    "    y_max = min(box_a[3], box_b[3])\n",
    "\n",
    "    inter_area = max(0, x_max - x_min + 1) * max(0, y_max - y_min + 1)\n",
    "\n",
    "    box_a_area = (box_a[2] - box_a[0] + 1) * (box_a[3] - box_a[1] + 1)\n",
    "    box_b_area = (box_b[2] - box_b[0] + 1) * (box_b[3] - box_b[1] + 1)\n",
    "\n",
    "    iou = inter_area / float(box_a_area + box_b_area - inter_area)\n",
    "\n",
    "    return iou"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_illegal_fields(annotations, current_image):\n",
    "     illegal_fields = set()\n",
    "     for annotation in annotations:\n",
    "        image_name, x_min, y_min, x_max, y_max, name = annotation.split()\n",
    "        if image_name == current_image:\n",
    "            zone = (int(x_min), int(y_min), int(x_max), int(y_max))\n",
    "            illegal_fields.add(zone)\n",
    "     return illegal_fields"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def distant_rand(a, b, x, d):\n",
    "    lb = max(a, x - d + 1)\n",
    "    ub = min(b, x + d - 1)\n",
    "    k = ub - lb + 1\n",
    "\n",
    "    if b-k < a:\n",
    "        return None\n",
    "    else:\n",
    "        y = np.random.randint(a, b - k)\n",
    "        if y > x - d:\n",
    "            y = y + k\n",
    "        return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_negative_examples(character, save_path, l=60, L=72, num_samples=28, iou_thresh=0.15, limit=100000):\n",
    "    global count\n",
    "\n",
    "    annotations = get_annotations(character)\n",
    "    used_files = set()\n",
    "\n",
    "    for annotation in tqdm(annotations):\n",
    "        image_name = annotation.split()[0]\n",
    "        if image_name not in used_files:\n",
    "            used_files.add(image_name)\n",
    "            illegal_fields = get_illegal_fields(annotations, image_name)\n",
    "\n",
    "            img = cv.imread(TRAIN_PATH + character + \"/\" + image_name)\n",
    "            num_cols = img.shape[0]\n",
    "            num_rows = img.shape[1]\n",
    "\n",
    "            point = (np.random.randint(low=0, high=num_rows - l), np.random.randint(low=0, high=num_cols - L))\n",
    "            for i in range(num_samples):\n",
    "                x = distant_rand(0, num_rows - l, point[0], 3 * l // 2)\n",
    "                y = distant_rand(0, num_cols - L, point[1], 3 * L // 2)\n",
    "                point = (x, y)\n",
    "\n",
    "                square = img[y: y + L, x: x + l]\n",
    "                scores = [intersection_over_union((x, y, x + l,  y + L), zone)\n",
    "                      for zone in illegal_fields]\n",
    "\n",
    "                if all(score <= iou_thresh for score in scores):\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\" , square)\n",
    "                    count += 1\n",
    "\n",
    "                if count > limit: return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "count = 0\n",
    "for character in CHARACTERS:\n",
    "    extract_negative_examples(character, NEGATIVE_PATH)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract positives from validation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_positives_validation():\n",
    "    annotations_file = open(VALIDATION_ANN + \"validare_annotations.txt\")\n",
    "    annotations = annotations_file.read().splitlines()\n",
    "    annotations_file.close()\n",
    "\n",
    "    count = 0\n",
    "    for annotation in tqdm(annotations):\n",
    "         image_name, x_min, y_min, x_max, y_max, name = annotation.split()\n",
    "         x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
    "\n",
    "         img = cv.imread(VALIDATION_PATH + image_name)\n",
    "         face = img[y_min:y_max, x_min:x_max, :]\n",
    "         count += 1\n",
    "         cv.imwrite(VALIDATION_P + str(count) + \".jpg\", face)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_positives_validation()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract negative examples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_negatives_validation(l=64, num_samples=5, iou_thresh=0.25, limit=1000):\n",
    "    annotations_file = open(VALIDATION_ANN + \"validare_annotations.txt\")\n",
    "    annotations = annotations_file.read().splitlines()\n",
    "    annotations_file.close()\n",
    "\n",
    "    used_files = set()\n",
    "    count = 0\n",
    "\n",
    "    for annotation in tqdm(annotations):\n",
    "        image_name = annotation.split()[0]\n",
    "        if image_name not in used_files:\n",
    "            used_files.add(image_name)\n",
    "            illegal_fields = get_illegal_fields(annotations, image_name)\n",
    "\n",
    "            img = cv.imread(TRAIN_PATH + character + \"/\" + image_name)\n",
    "            num_cols = img.shape[0]\n",
    "            num_rows = img.shape[1]\n",
    "\n",
    "            point = (np.random.randint(low=0, high=num_rows - l), np.random.randint(low=0, high=num_cols - l))\n",
    "            for i in range(num_samples):\n",
    "                x = distant_rand(0, num_rows - l, point[0], 2 * l)\n",
    "                y = distant_rand(0, num_cols - l, point[1], 2 * l)\n",
    "                point = (x, y)\n",
    "\n",
    "                square = img[y: y + l, x: x + l]\n",
    "                scores = [intersection_over_union((x, y, x + l,  y + l), zone)\n",
    "                      for zone in illegal_fields]\n",
    "\n",
    "                if all(score <= iou_thresh for score in scores):\n",
    "                    cv.imwrite(VALIDATION_N + str(count) + \".jpg\" , square)\n",
    "                    count += 1\n",
    "\n",
    "                if count > limit: return"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_negatives_validation()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "def get_more_from_character(character, source, positive_path, cutout=15):\n",
    "    global count\n",
    "    border = 0\n",
    "\n",
    "    source += (character + \"/\")\n",
    "    annotations = get_annotations(character)\n",
    "\n",
    "\n",
    "    for annotation in tqdm(annotations):\n",
    "        image_name, x_min, y_min, x_max, y_max, name = annotation.split()\n",
    "        x_min, y_min, x_max, y_max = int(x_min), int(y_min), int(x_max), int(y_max)\n",
    "\n",
    "        if name != \"unkonwn\":\n",
    "            save_path = positive_path + name + \"/\"\n",
    "            img = cv.imread(source + image_name)\n",
    "            face = img[y_min:y_max, x_min:x_max, :]\n",
    "            count += 1\n",
    "            cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "            pos = [x_min - cutout, x_max + cutout, y_min - cutout, y_max + cutout]\n",
    "            if is_valid_position(img, pos):\n",
    "                face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                count += 1\n",
    "                cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "            if img.shape[0] >= 30 and img.shape[1] >= 30:\n",
    "                pos = [x_min, x_max, y_min, y_max]\n",
    "                pos[border % 4] += cutout\n",
    "                if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "                pos[border % 4] -= 2*cutout\n",
    "                if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "            if border % 2 == 0:\n",
    "                pos = [x_min - cutout // 2, x_max, y_min - cutout // 2, y_max]\n",
    "                if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "                    pos = [x_min + cutout // 2, x_max, y_min + cutout // 2, y_max]\n",
    "                if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "            elif border % 2 == 1:\n",
    "                pos = [x_min, x_max + cutout // 2, y_min, y_max + cutout // 2]\n",
    "                if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "                pos = [x_min, x_max + cutout // 2, y_min, y_max + cutout // 2]\n",
    "                if is_valid_position(img, pos):\n",
    "                    face = img[pos[2]:pos[3], pos[0]:pos[1], :]\n",
    "                    count += 1\n",
    "                    cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "            l = x_max - x_min + 1\n",
    "            L = y_max - y_min + 1\n",
    "            l = max(L, l)\n",
    "            face = img[y_min:y_min + l, x_min:x_min + l]\n",
    "            count += 1\n",
    "            cv.imwrite(save_path + str(count) + \".jpg\", face)\n",
    "\n",
    "        border += 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
